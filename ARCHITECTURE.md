# Project Architecture

This document explains the modular structure of the job scraper.

## ğŸ“ Directory Structure

```
.
â”œâ”€â”€ scraper.js              # Main orchestrator
â”œâ”€â”€ server.js               # Express web server
â”œâ”€â”€ scrapers/               # Individual job board scrapers
â”‚   â”œâ”€â”€ ashby.js           # Ashby scraper
â”‚   â”œâ”€â”€ greenhouse.js      # Greenhouse scraper
â”‚   â”œâ”€â”€ lever.js           # Lever scraper
â”‚   â””â”€â”€ workable.js        # Workable scraper
â”œâ”€â”€ utils/                  # Shared utilities
â”‚   â”œâ”€â”€ helpers.js         # Common functions (delay, stripHtml, etc.)
â”‚   â””â”€â”€ serp.js            # SERP API search functionality
â””â”€â”€ public/                 # Frontend files
    â”œâ”€â”€ index.html
    â”œâ”€â”€ app.js
    â”œâ”€â”€ styles.css
    â””â”€â”€ toast-modal.css
```

## ğŸ”§ How It Works

### 1. **Main Orchestrator** (`scraper.js`)
- Coordinates the entire scraping process
- Calls SERP API to discover companies with recent job postings
- Delegates scraping to individual job board modules
- Aggregates all results into `jobs.json`

### 2. **Scrapers** (`scrapers/*.js`)
Each scraper module exports:
- `extractXSlug(url)` - Extracts company identifier from URL
- `fetchXJobs(org)` - Gets job listings from the job board
- `fetchXDetail(org, jobId)` - Gets full job details (if needed)
- `scrapeX(orgs, all)` - Main scraping function that populates the results array

**Benefits:**
- âœ… Easy to debug individual job boards
- âœ… Easy to add new job boards (just create a new file)
- âœ… Easy to disable a job board (comment out the import)
- âœ… Clear separation of concerns

### 3. **Utilities** (`utils/*.js`)
Shared functionality used across all scrapers:
- `delay(ms)` - Rate limiting helper
- `stripHtml(html)` - Removes HTML tags from descriptions
- `serpSearch(site, keyword, daysBack)` - SERP API integration

### 4. **Web Server** (`server.js`)
- Serves the frontend dashboard
- Runs the scraper daily
- Provides `/jobs` API endpoint

## ğŸš€ Adding a New Job Board

To add a new job board (e.g., "SmartRecruiters"):

1. Create `scrapers/smartrecruiters.js`:
```javascript
import { delay, stripHtml } from "../utils/helpers.js";

export function extractSmartRecruitersSlug(url) {
  // Extract company identifier from URL
}

export async function fetchSmartRecruitersJobs(company) {
  // Fetch job listings
}

export async function scrapeSmartRecruiters(companies, all) {
  // Main scraping logic
}
```

2. Update `scraper.js`:
```javascript
import { 
  extractSmartRecruitersSlug, 
  scrapeSmartRecruiters 
} from "./scrapers/smartrecruiters.js";

// In main():
const smartrecruitersLinks = await serpSearch("jobs.smartrecruiters.com", ARG_SEARCH, ARG_DAYS);
const smartrecruitersOrgs = [...new Set(smartrecruitersLinks.map(extractSmartRecruitersSlug).filter(Boolean))];

await scrapeSmartRecruiters(smartrecruitersOrgs, all);
```

3. Update the frontend (`public/index.html`, `public/styles.css`) to include the new source.

That's it! The modular structure makes it easy to scale.

## ğŸ” Rate Limiting

Each scraper implements rate limiting to avoid 429 errors:
- 1000ms delay between companies
- 800ms delay between job detail requests

Adjust these values in individual scraper files if needed.

## ğŸŒ Environment Variables

- `SERP_API_KEY` - Your SerpAPI key
- `SEARCH_QUERY` - Optional search keyword (default: "")
- `DAYS_BACK` - How many days back to search (default: 3)
- `PORT` - Web server port (default: 8080)

